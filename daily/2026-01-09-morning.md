# ğŸ§  ç§‘ç ” & æŠ€æœ¯çƒ­ç‚¹æ—¥æŠ¥

æ—¥æœŸï¼š2026-01-09 ä¸Šåˆ
ç”Ÿæˆæ—¶é—´ï¼š2026/01/09 10:54

## ğŸ”¥ AI / LLM

- **Mastering the Game of Go with Self-play Experience Replay**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03306v1 Announce Type: new  Abstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03306

- **Digital Red Queen: Adversarial Program Evolution in Core War with LLMs**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03335v1 Announce Type: new  Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embrace...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03335

- **Lightweight Transformer Architectures for Edge Devices in Real-Time Applications**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03290v1 Announce Type: new  Abstract: The deployment of transformer-based models on resource-constrained edge devices represents a critical challenge in enabling real-time artificial intelligence applications. This comprehensive survey examines lightweight transformer architectures specifically designed for edge deployment, analyzing recent advances in model compression, quantization, pruning, and knowledge distillation techniques. We systematically review prominent lightweight varian...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03290

- **Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts**  
  æ¥æºï¼šarXiv cs.LG (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03315v1 Announce Type: new  Abstract: We report a case study of four end-to-end attempts to autonomously generate ML research papers using a pipeline of six LLM agents mapped to stages of the scientific workflow. Of these four, three attempts failed during implementation or evaluation. One completed the pipeline and was accepted to Agents4Science 2025, an experimental inaugural venue that required AI systems as first authors, passing both human and multi-AI review. From these attempts...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03315

- **Netomiâ€™s lessons for scaling agentic systems into the enterprise**  
  æ¥æºï¼šOpenAI Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šHow Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2â€”combining concurrency, governance, and multi-step reasoning for reliable production workflows.
  é“¾æ¥ï¼šhttps://openai.com/index/netomi

## ğŸ”¥ Agent / æ™ºèƒ½ä½“

- **Mastering the Game of Go with Self-play Experience Replay**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03306v1 Announce Type: new  Abstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03306

- **Digital Red Queen: Adversarial Program Evolution in Core War with LLMs**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03335v1 Announce Type: new  Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embrace...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03335

- **Agentic AI: teaching machines to think like scientists - Drug Target Review**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šAgentic AI: teaching machines to think like scientistsÂ Â Drug Target Review
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMipAFBVV95cUxQVDdNSzk1UlNvOXg5NG1ER1ZtdFNhNlI1R2Q2cjhidmU2YXZKQkNzTE1NUDE5YXFVdUlIdzZtMU5hLUhObzdzUzh3VXp2QU5YdUlpaWdZRVNkUUlySFNHa25ZQjlQTHNMRkJMVGZaYWZmNUtQYXdLcXFDUHhLa1V6WnZhODVKbmlUaWRhNTZycFM2aWd6OVJIVnRGNWVoVktiSEttRQ?oc=5

- **AI agents arrived in 2025 â€“ hereâ€™s what happened and the challenges ahead in 2026 - The Conversation**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šAI agents arrived in 2025 â€“ hereâ€™s what happened and the challenges ahead in 2026Â Â The Conversation
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiswFBVV95cUxOSlpra254dTIzTVRYT3FOZ09YY2NBYjhNZDVDWElwQlk2czRCTlAyV0hFODVvakQxTXVJSjQ2Nlp6U0d1TzRfZjJDYzVNd2VVOGJqMlhQWUY4ZmlpRTdtYXhRdG01V2dWbERXOTFqQ0VYT25CcXpwYUZESmZfS2ZRTTI1SHg2b1VHQU05ZHMwRGp1TEs1UkhxZDNHNVQyRVBlSGVHNC1LRG1aSzVnc3NndnJLdw?oc=5

- **This AI Paper from Stanford and Harvard Explains Why Most â€˜Agentic AIâ€™ Systems Feel Impressive in Demos and then Completely Fall Apart in Real Use - MarkTechPost**  
  æ¥æºï¼šGoogle News - AI Agents (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šThis AI Paper from Stanford and Harvard Explains Why Most â€˜Agentic AIâ€™ Systems Feel Impressive in Demos and then Completely Fall Apart in Real UseÂ Â MarkTechPost
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMikwJBVV95cUxOaWtlTDBheTdzSnpoaXhYaUxQZmVTNlhCeWpMM01XZUdLaFpaRUlhTHp6R3NLVERNVnkzeVB3cXdsTWxhM2k2V1R2ZWY2WHZfRXZWeWRGNEFEX3RjUENrR0dGNDk5UzlNS3V0TFh0aGRKcUNJRmtlUUxveFpETF9ScFVUTEtBMmtpc3VsTm5TX0VVWlh5d0ptcHFOTWE5VldPaFpQRzBsM0dfQ0xpYm9JcUZuUlBVTWdieDg1aXRrNDBTZ2RTM3A4VkNPdzFXYWVCam1mb2tIczJvZk9ySDNGQjd2dGYzVUY4dkxHQzgwTVIxMXlwQzZhT2xqSDZYRm90ckJCcm9pMmZPMmxpRUowcmppWdIBmAJBVV95cUxPSHQ5VDYwaGVCMzg2NlJGVjZMQUpDNGRhbGdacDBQOHVubW1JdHlqUkJ2WERhNVJ4LWZ5WnNWczRWNnFYaXZfeVh0cE5GaGgyTUIyME1ucmlRaEx2bXNMYTBSV25NbzhqM1Awb0VtQ200SHRONGlieHdvOGlKNWUyNlY2a2JhRkdRM1h5aXJGYmVsSWxVM1R4NEIzZEx3dEFvbHg1d1JXUFdheHk2cjVLenBXQVU3SXRHM2ZkdE1VbTAzd3NSNS1Wd1dGQVdGVG5wRzZfSC16SDlYalNOTFZ0VU1BbFc4bWh5b0x1ZXY1S04zSVRDVmxxaDItNWpUbDJacURTVDJrTXlqUVh2ME9TS3N2MEk0aTZp?oc=5

## ğŸ”¥ RAG / æ£€ç´¢å¢å¼ºç”Ÿæˆ

- **Mastering the Game of Go with Self-play Experience Replay**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03306v1 Announce Type: new  Abstract: The game of Go has long served as a benchmark for artificial intelligence, demanding sophisticated strategic reasoning and long-term planning. Previous approaches such as AlphaGo and its successors, have predominantly relied on model-based Monte-Carlo Tree Search (MCTS). In this work, we present QZero, a novel model-free reinforcement learning algorithm that forgoes search during training and learns a Nash equilibrium policy through self-play and...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03306

- **Digital Red Queen: Adversarial Program Evolution in Core War with LLMs**  
  æ¥æºï¼šarXiv cs.AI (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03335v1 Announce Type: new  Abstract: Large language models (LLMs) are increasingly being used to evolve solutions to problems in many domains, in a process inspired by biological evolution. However, unlike biological evolution, most LLM-evolution frameworks are formulated as static optimization problems, overlooking the open-ended adversarial dynamics that characterize real-world evolutionary processes. Here, we study Digital Red Queen (DRQ), a simple self-play algorithm that embrace...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03335

- **Enhancing Retrieval-Augmented Generation with Two-Stage Retrieval: FlashRank Reranking and Query Expansion**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03258v1 Announce Type: new  Abstract: Retrieval-Augmented Generation (RAG) couples a retriever with a large language model (LLM) to ground generated responses in external evidence. While this framework enhances factuality and domain adaptability, it faces a key bottleneck: balancing retrieval recall with limited LLM context. Retrieving too few passages risks missing critical context, while retrieving too many overwhelms the prompt window, diluting relevance and increasing cost.   We p...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03258

- **LLMDiRec: LLM-Enhanced Intent Diffusion for Sequential Recommendation**  
  æ¥æºï¼šarXiv cs.IR (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03259v1 Announce Type: new  Abstract: Existing sequential recommendation models, even advanced diffusion-based approaches, often struggle to capture the rich semantic intent underlying user behavior, especially for new users or long-tail items. This limitation stems from their reliance on ID-based embeddings, which lack semantic grounding. We introduce LLMDiRec, a new approach that addresses this gap by integrating Large Language Models (LLMs) into an intent-aware diffusion model. Our...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03259

- **Databricks says its Instructed Retriever offers better AI answers than RAG in the enterprise - InfoWorld**  
  æ¥æºï¼šGoogle News - RAG (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šDatabricks says its Instructed Retriever offers better AI answers than RAG in the enterpriseÂ Â InfoWorld
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMi1gFBVV95cUxNSHlKVnBmT3hrV1V1aWFWWDlhQy13ek1Jd29rczVMVC1mdUpBaFZGTjRiY1ZsRGhTcEhTaUgwQWJVci1XZmNWVThNMnlTYVNPSXUxdTV0dDVPUzFjRVhocmwyNGZSQ05ZX3psRTFWeGg1d1E5NjhtVE81SERtNFNYTlVvOUVfRHZRZTlLLUpiOW9WSUxzbFFMWHFmQXNIaGY0M2lqUG4yaE5JVE9qdEdocnIyNUdvV0NUVU5iYmNuRVZqN01Rb2x2Nl9ja29mVGo0cFBXVDRR?oc=5

## ğŸ”¥ LLM / å¤§è¯­è¨€æ¨¡å‹

- **DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03261v1 Announce Type: new  Abstract: Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context blindness in noisy environments. To bridge this gap, we propose DeepResearch-Slice, a simple yet effective neuro-symbolic framework. Unlike implicit attention, our approach predicts precise span indi...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03261

- **Internal Reasoning vs. External Control: A Thermodynamic Analysis of Sycophancy in Large Language Models**  
  æ¥æºï¼šarXiv cs.CL (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03263v1 Announce Type: new  Abstract: Large Language Models frequently exhibit sycophancy, prioritizing user agreeableness over correctness. We investigate whether this requires external regulation or can be mitigated by internal reasoning alone. Using CAP-GSM8K (N=500), an adversarial dataset, we evaluate internal (CoT) versus external (RCA) mechanisms across GPT-3.5, GPT-4o, and GPT-5.1. Our results reveal the structural limits of internal reasoning: it causes performance collapse i...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03263

- **A new way to increase the capabilities of large language models - MIT News**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šA new way to increase the capabilities of large language modelsÂ Â MIT News
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMijAFBVV95cUxOOV9IaTNEem5RRVJVQ1p4TmVzYTdRUWhpY3lYQ2lLQ0dNd1dOdlhtbVN3OFVoRHVIVy1keDRIUndSNzNySlVxaEhXUF9OTVhGeDRfVXB3Z2VBcjh4QVNobF9XM041QjFaaHM4M3NkN0Zhdy1SZGFyb3ZOTmU3LXp5X1JHRE1taUtabFZIZg?oc=5

- **Large Language Models in Legal Systems: A Survey - Nature**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šLarge Language Models in Legal Systems: A SurveyÂ Â Nature
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMiX0FVX3lxTE54b3lqVWRRUDE1MUU0Rzc0enRvTVZUUG43OUhSTl81UThaZ0N6ZlJ3MGQzTml2akxQVE9Geld1TUFJLTQ5cTlWdTgzdmhvSC1KdEp3aER2REwydnJDTHp3?oc=5

- **Advanced Research Computing expands large language model access - Virginia Tech News**  
  æ¥æºï¼šGoogle News - LLM (æ–°é—»)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šAdvanced Research Computing expands large language model accessÂ Â Virginia Tech News
  é“¾æ¥ï¼šhttps://news.google.com/rss/articles/CBMib0FVX3lxTFB0d3pCVUJEbVFMd2FBRHkyM1h5MTlvY0pqOEd3Q2xKengzQVR1UWk2OGRVOFdaZWNsQ29XQkp6VHYwelBSdmtJT2wtc3B4NndNXy1NZmdRamhZX2dOUTFvWWs1Z1hKdEVEQmtILU9oZw?oc=5

## ğŸ”¥ è®¡ç®—æœºç§‘å­¦ / è½¯ä»¶å·¥ç¨‹

- **The Anatomy of a Successful Student Scrum Team: Motivation, Personalities, and Academic Adaptation**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03364v1 Announce Type: new  Abstract: Agile methods, and Scrum in particular, are widely taught in software engineering education; however, there is limited empirical evidence on how these practices function in long-running, student-led projects under academic and hybrid work constraints. This paper presents a year-long case study of an eight-person student development team tasked with designing and implementing a virtual reality game that simulates a university campus and provides pr...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03364

- **RepoShapley: Shapley-Enhanced Context Filtering for Repository-Level Code Completion**  
  æ¥æºï¼šarXiv cs.SE (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03378v1 Announce Type: new  Abstract: Repository-level code completion benefits from retrieval-augmented generation (RAG). However, controlling cross-file evidence is difficult because chunk utility is often interaction-dependent: some snippets help only when paired with complementary context, while others harm decoding when they conflict. We propose RepoShapley, a coalition-aware context filtering framework supervised by Shapley-style marginal contributions. Our module ChunkShapley c...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03378

- **Revisiting Speculative Leaderless Protocols for Low-Latency BFT Replication**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03390v1 Announce Type: new  Abstract: As Byzantine Fault Tolerant (BFT) protocols begin to be used in permissioned blockchains for user-facing applications such as payments, it is crucial that they provide low latency. In pursuit of low latency, some recently proposed BFT consensus protocols employ a leaderless optimistic fast path, in which clients broadcast their requests directly to replicas without first serializing requests at a leader, resulting in an end-to-end commit latency o...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03390

- **Majorum: Ebb-and-Flow Consensus with Dynamic Quorums**  
  æ¥æºï¼šarXiv cs.DC (arXivï¼ˆè®ºæ–‡æ‘˜è¦ï¼‰)  
  æ‘˜è¦ï¼ˆRSSæ‘˜è¦ï¼‰ï¼šarXiv:2601.03862v1 Announce Type: new  Abstract: Dynamic availability is the ability of a consensus protocol to remain live despite honest participants going offline and later rejoining. A well-known limitation is that dynamically available protocols, on their own, cannot provide strong safety guarantees during network partitions or extended asynchrony. Ebb-and-flow protocols [SP21] address this by combining a dynamically available protocol with a partially synchronous finality protocol that irr...
  é“¾æ¥ï¼šhttps://arxiv.org/abs/2601.03862

- **Why AI is pushing developers toward typed languages**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šCassidy Williams @cassidoo Cassidy is senior director for developer advocacy here at GitHub. She enjoys building software, advising startups, and teaching developers how to build better. She has a weekly newsletter at cassidoo.co/newsletter where you can get her updates, practice coding problems, and a joke in your inbox!
  é“¾æ¥ï¼šhttps://github.blog/ai-and-ml/llms/why-ai-is-pushing-developers-toward-typed-languages/

## ğŸ”¥ å·¥ç¨‹ / ç³»ç»Ÿ / å·¥å…·

- **Why AI is pushing developers toward typed languages**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šCassidy Williams @cassidoo Cassidy is senior director for developer advocacy here at GitHub. She enjoys building software, advising startups, and teaching developers how to build better. She has a weekly newsletter at cassidoo.co/newsletter where you can get her updates, practice coding problems, and a joke in your inbox!
  é“¾æ¥ï¼šhttps://github.blog/ai-and-ml/llms/why-ai-is-pushing-developers-toward-typed-languages/

- **Agentic AI, MCP, and spec-driven development: Top blog posts of 2025**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šHome / Developer skills Agentic AI, MCP, and spec-driven development: Top blog posts of 2025 Explore the GitHub Blogâ€™s top posts covering the biggest software development topics of the year. Natalie GuevaraÂ·@naguevara December 30, 2025 | 4 minutes Share: As the editor of the GitHub Blog, I get a front-row seat to everything thatâ€™s published here. As we wrap up 2025, Iâ€™m marking the occasion by looking back at the most popular blog posts of the year as well as some of my favorite interviews. Whil...
  é“¾æ¥ï¼šhttps://github.blog/developer-skills/agentic-ai-mcp-and-spec-driven-development-top-blog-posts-of-2025/

- **Bugs that survive the heat of continuous fuzzing**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šHome / Security / Vulnerability research Bugs that survive the heat of continuous fuzzing Learn why some long-enrolled OSS-Fuzz projects still contain vulnerabilities and how you can find them. Antonio MoralesÂ·@antonio-morales December 29, 2025 | 17 minutes Share: Even when a project has been intensively fuzzed for years, bugs can still survive. â€‹â€‹OSS-Fuzz is one of the most impactful security initiatives in open source. In collaboration with the OpenSSF Foundation, it has helped to find thousan...
  é“¾æ¥ï¼šhttps://github.blog/security/vulnerability-research/bugs-that-survive-the-heat-of-continuous-fuzzing/

- **WRAP up your backlog with GitHub Copilot coding agent**  
  æ¥æºï¼šGitHub Blog (åšå®¢)  
  æ‘˜è¦ï¼ˆå…¨æ–‡ï¼‰ï¼šHome / AI & ML / GitHub Copilot WRAP up your backlog with GitHub Copilot coding agent An easy-to-remember acronym, WRAP will help you write effective issues, refine your instructions, and get the most out of Copilot coding agent. Brittany Ellich & Jason Etcovitch December 26, 2025 | 6 minutes Share: Engineers at GitHub have been using GitHub Copilot coding agent for over a year now, studying through experience where it can help save developers real time and energy. Through our work, we have deve...
  é“¾æ¥ï¼šhttps://github.blog/ai-and-ml/github-copilot/wrap-up-your-backlog-with-github-copilot-coding-agent/

---
_è‡ªåŠ¨ç”Ÿæˆ Â· GitHub Actions_
